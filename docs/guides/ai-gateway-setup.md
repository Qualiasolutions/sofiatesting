# AI Gateway Setup Complete ✅

## What Was Done

### 1. **Added Gemini 2.5 Flash** (Default Model)
- Model ID: `google/gemini-2.5-flash`
- Cost: $0.30/M input, $2.50/M output
- **8x cheaper than Grok** for WhatsApp volume
- Routes through Vercel AI Gateway

### 2. **Added Claude 3.7 Sonnet** (Best Accuracy)
- Model ID: `anthropic/claude-3.7-sonnet`
- Cost: $3.00/M input, $15.00/M output
- **Best for zero-error document generation**
- Routes through Vercel AI Gateway

### 3. **Configured OIDC Authentication**
- ✅ Project linked to Vercel: `sofiatesting`
- ✅ OIDC token pulled for local development
- ✅ File: `.env.development.local` created with `VERCEL_OIDC_TOKEN`

### 4. **All Models Route Through Vercel AI Gateway**
```typescript
// lib/ai/providers.ts
"chat-model-gemini": gateway.languageModel("google/gemini-2.5-flash"),
"chat-model-claude": gateway.languageModel("anthropic/claude-3.7-sonnet"),
"chat-model": gateway.languageModel("xai/grok-2-vision-1212"),
"chat-model-reasoning": gateway.languageModel("xai/grok-3-mini"),
```

## How It Works

### Production Deployment (Vercel)
- **Zero configuration needed**
- OIDC tokens generated automatically
- All costs billed through Vercel AI Gateway
- Unified monitoring and observability

### Local Development
```bash
# Refresh OIDC token every 12 hours (token expires)
vercel env pull .env.development.local

# Start development server
pnpm dev
```

### WhatsApp Deployment
- Use Gemini 2.5 Flash (default) for volume
- Switch to Claude 3.7 if you need 100% accuracy
- All billing goes through your Vercel account

## Cost Comparison (10k messages/day)

| Model | Daily Cost | Best For |
|-------|-----------|----------|
| **Gemini 2.5 Flash** ⭐ | ~$12 | WhatsApp volume (DEFAULT) |
| **Claude 3.7 Sonnet** | ~$60 | Zero-error legal documents |
| Grok Vision | ~$50 | Vision tasks |
| Grok Reasoning | ~$50 | Complex reasoning |

## Model Selection in UI

Users can switch models in the dropdown:
- Gemini 2.5 Flash (default, cheapest)
- Claude 3.7 Sonnet (best accuracy)
- Grok Vision (multimodal)
- Grok Reasoning (advanced reasoning)

## Environment Variables

### Required for Local Dev
```bash
# .env.development.local (auto-generated by vercel env pull)
VERCEL_OIDC_TOKEN="..."  # Auto-refreshed by Vercel CLI
```

### NOT Required
- ❌ `AI_GATEWAY_API_KEY` - Only needed for non-Vercel deployments
- ❌ `GOOGLE_GENERATIVE_AI_API_KEY` - Using gateway, not direct API
- ❌ `ANTHROPIC_API_KEY` - Using gateway, not direct API

## Deployment Commands

### Local Development
```bash
# Pull latest OIDC token
vercel env pull .env.development.local

# Start dev server
pnpm dev
```

### Deploy to Production
```bash
# Deploy to Vercel
vercel --prod

# Or use GitHub integration (auto-deploy on push)
```

## Monitoring & Observability

View all AI requests, costs, and usage:
1. Go to [Vercel Dashboard](https://vercel.com/dashboard)
2. Click **AI Gateway** tab
3. View usage, costs, and request logs

## Provider Options (Advanced)

You can control routing and fallbacks:

```typescript
// Example: Prefer specific providers
streamText({
  model: 'google/gemini-2.5-flash',
  providerOptions: {
    gateway: {
      order: ['google', 'vertex'], // Try Google first, then Vertex AI
      models: ['google/gemini-2.0-flash'], // Fallback model
    }
  }
})
```

## Next Steps

1. **Test locally**: Run `pnpm dev` and test chat with Gemini
2. **Deploy to Vercel**: Run `vercel --prod`
3. **Monitor costs**: Check AI Gateway dashboard
4. **Integrate WhatsApp**: Connect via webhook to your API route

## Troubleshooting

### OIDC Token Expired
```bash
# Error: OIDC token expired (after 12 hours)
# Solution: Pull new token
vercel env pull .env.development.local
```

### Model Not Available
- Check [AI Gateway Models](https://vercel.com/ai-gateway/models) for availability
- Verify model ID format: `provider/model-name`

### High Costs
- Switch default from Claude to Gemini in `lib/ai/models.ts`
- Monitor usage in Vercel AI Gateway dashboard
- Set up budget alerts in Vercel settings

## Architecture

```
User Request
    ↓
Next.js API Route (app/api/chat/route.ts)
    ↓
AI SDK Gateway Provider (lib/ai/providers.ts)
    ↓
Vercel AI Gateway (OIDC Auth)
    ↓
Provider (Google/Anthropic/xAI)
    ↓
Response → User
```

All requests flow through Vercel AI Gateway with automatic:
- Load balancing
- Fallback handling
- Cost tracking
- Usage monitoring
- OIDC authentication
